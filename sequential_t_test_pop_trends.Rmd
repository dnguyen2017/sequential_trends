---
title: "Sequential t-test"
author: "David Nguyen"
date: "Compliled on `r Sys.Date()`"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

# apply FUNC cumulatively when NA are present
# https://stackoverflow.com/questions/25576358/calculate-cumsum-while-ignoring-na-values/25576972
cumSkipNA <- function(x, FUNC)
{
  d <- deparse(substitute(FUNC))
  funs <- c("max", "min", "prod", "sum")
  stopifnot(is.vector(x), is.numeric(x), d %in% funs)
  FUNC <- match.fun(paste0("cum", d))
  x[!is.na(x)] <- FUNC(x[!is.na(x)])
  x
}

run_stat <- function(x,
                     alternative = NA,
                     null = 0) {
  # add checks here
  
  # init vectors for statistics
  m_ <- vector("numeric", length = length(x))
  s_ <- sd_0 <- s_0 <- s2_mle <- sd_mle <- s2_ <- sd_ <- m_
  
  if (is.na(alternative)) { # if alternative hypothesis is one sided and composite
    # init value of mean is x1. All other init values are 0
    m_[1] <- x[1]
    
    # calculate running statistics
    for (i in 2:length(x)) {
      m_[i] <- m_[i - 1] + (x[i] - m_[i - 1]) / i
      s_[i]  <- s_[i - 1] + (x[i] - m_[i - 1]) * (x[i] - m_[i])
      s2_mle[i] <- s_[i] / (i)
      sd_mle[i] <- sqrt(s2_mle[i])
      s2_[i] <- s_[i] / (i - 1)
      sd_[i] <- sqrt(s2_[i])
      # under null that r = 0
      s_0[i] <- s_0[i - 1] + (x[i] - 0) * (x[i] - 0)
      sd_0[i] <- sqrt(s_0[i] / i)
    }    
    
  } else { # if alternative is point hypothesis
    m_[1] <- alternative
    # calculate running statistics
    for (i in 2:length(x)) {
      m_[i] <- alternative + (x[i] - alternative) / i
      s_[i]  <- s_[i - 1] + (x[i] - alternative) * (x[i] - alternative)
      s2_mle[i] <- s_[i] / (i)
      sd_mle[i] <- sqrt(s2_mle[i])
      #s2_[i] <- s_[i]/(i-1)
      #sd_[i] <- sqrt(s2_[i])
      # under null that r = 0
      s_0[i] <- s_0[i - 1] + (x[i] - null) * (x[i] - null)
      sd_0[i] <- sqrt(s_0[i] / i)
    }
  }
  # return: id = observation number, obs = observation value, mu_mle, sd_mle, sd_corrected
  return(tidyr::tibble(
    diff_1 = x,
    mu_mle = m_,
    sd_mle,
    #sd_corrected = sd_,
    sd_null = sd_0
  )) # %>% tibble::rowid_to_column(var = "id"))
  #return(tidyr::tibble(diff_1 = c(NA,x), mu_mle = c(NA,m_), sd_mle = c(NA,sd_mle), sd_corrected = c(NA,sd_) )) # %>% tibble::rowid_to_column(var = "id"))
}
```

# Testing for linear and exponential population trends

Stochastic linear trends in population size $N_t$ for $t = 0,1,2, \ldots, T$ can be described as a Gaussian random walk with drift $r$ and environmental process standard deviation $\sigma$.

\begin{align}
N_{t+1} & \sim Normal(n_t + r, \sigma) \\
N_{0} & = n_0
\end{align}

This can also be used as a model of the log-population size $X_t$ of a model with stochastic exponential growth model with lognormal environmental noise.

\begin{align}
X_{t+1} & \sim Normal(x_t + r, \sigma) \\
X_{0} & = x_0
\end{align}

The first differences of the observed population sizes are 

\begin{align}
d_1, \ldots, d_{T-1} & =  
\begin{cases}
n_1 - n_0, \ldots, n_T - n_{T-1} \text{ for linear model} \\
x_1 - x_0, \ldots, x_T - x_{T-1} \text{ for exponential model} \\
\end{cases} \\
                     & \overset{iid}\sim Normal(r, \sigma) \\
\end{align}

Since the first differences are independent and identically distributed normal random variables with mean equal to the linear (additive) or exponential (multiplicative) trend we can test for non-zero trends using the null hypothesis of $r = 0$ and alternative hypothesis $r \neq 0$.

# Magnitude of conservation relevant trends

Estimated trends in population reduction are included as in the IUCN Red list as one of five criteria for classifying threatened taxa (criterion A). The IUCN has defined intervals of percent population decline for categorization of threatened taxa as criticaly endangered, endangered, and vulnerable. The lower bound of these intervals can be used to make decisions about how to subset the parameter space of trend ($r$) for testing hypotheses about whether a population is declining, and if so, what threat category to assign based on criteria A. 

```{r}
# https://nc.iucnredlist.org/redlist/content/attachment_files/summary_sheet_en_web.pdf
iucn_crit <- expand_grid(subcriteria = c("A1", "A2, A3, A4"),
                         category = c("Critically endangered", "endangered", "vulnerable")) %>%
  add_column(threshold = c(0.9, 0.7, 0.5, 0.8, 0.5, 0.3))


timespan = 9 # for decadal trend assuming initial population size at t = 0
# compute trend parameter to satisfy IUCN threshold
iucn_crit <- 
  iucn_crit %>%
  mutate(trend = log(1-threshold)/timespan
         ,linear_trend = -(1 - threshold) / timespan)

iucn_crit %>% 
  mutate(threshold = paste(threshold*100, "%")) %>%
  arrange(category) %>%
  knitr::kable(digits = 3, caption = "IUCN Red List criteria A",
               col.names = c("sub-criteria", "threat category", "10-year % decrease", "exp. trend (r)", "lin. trend (r)" ))
```

```{r}
iucn_crit %>%
  rowwise() %>%
  mutate(traj = list(exp(trend*0:9))) %>%
  unnest(traj) %>%
  group_by(category, subcriteria) %>%
  mutate(time = row_number()) %>%
  ggplot() +
  geom_line(aes(x = time, y = traj, col = category)) +
  facet_wrap(~subcriteria) +
  ylim(-0.1,1.1)
```

# Example of defining null and alternative hypothesis using IUCN criteria A

In a null hypothesis testing framework, deciding if a population was critically endangered there are multiple hypotheses that could be tested. For instance:

* Stochastic exponential decline and subcriteria A1: $H_0: r = 0$ and $H_1: r < -0.256$
* Stochastic exponential decline and subcriteria A2 or A4: $H_0: r = 0$ and $H_1: r < -0.179$

```{r }
# simulate data
set.seed(123)

# set params
nreplicates <- 100
effect_size <- seq(0, by = 0.5, length.out = 6)
d_true_vec <- rep(effect_size, each = nreplicates)
d_relevant <- 0.5
d_relevant_vec <- rep(d_relevant, length = length(d_true_vec))
tmax <- 100

# simulate differences
diff_list <- lapply(seq_along(d_true_vec), function(x) rnorm(n = tmax, mean = d_true_vec[x], sd = 1))
```
                    
### sample size for fixed-sample one-sided t test
```{r}
# fixed sample size effect size for one sided t-test
# assume sd is known
tibble(effect_size = effect_size[effect_size > 0]) %>%
  rowwise() %>%
  mutate(sample_size =  power.t.test(delta = effect_size, sd = 1, sig.level = 0.05, power = 0.8, 
                                     type = "one.sample", alternative = "one.sided")$n,
         sample_size = ceiling(sample_size)) %>%
  # rowwise() %>%
  # mutate(sample_size = power_t$n)
  knitr::kable()
```

Sample size calculations for the fixed sample test assume that the unknown parameters $r,\sigma$ are known. For these sample size calculations I set a 0.05 type I error rate, 0.8 power which is the same as the nominal error probabilities I used for the sequential test.

### Effect of optional stopping on error rates for fixed-sample t-test

```{r cache = TRUE}
set.seed(123)
# initialize list to store results
ntsim <- 2000
small_effects <- rep(c(0,0.05,0.1), each = ntsim)
sim_dat_ttest <- lapply(seq_along(small_effects), function(x) rnorm(n = tmax, mean = small_effects[x], sd = 1))

ttest_list <- vector("list", length = length(sim_dat_ttest))

# for each time series, apply the one sided t-test after every observation
# stop and make decision at first time p < 0.05
# return a list containing t.test object
for (tseries in seq_along(sim_dat_ttest)) {
  
  for (samp in 2:tmax) {
    # calc t test repeatedly as data "accumulates"
    ttest_list[[tseries]] <- t.test(sim_dat_ttest[[tseries]][1:samp], alternative = "greater", conf.level = 0.95)
    
    # stop if p-value < 0.05
    if (ttest_list[[tseries]]$p.value < 0.05) break
  }
}

# make a df from the list of t.test objects
unlisted <- unlist(ttest_list)
rep_t_df <- tibble(true_effect = small_effects
      ,p = unlisted[names(unlisted) == "p.value"] %>% as.numeric()
      , sample_size = unlisted[names(unlisted) == "parameter.df"] %>% as.numeric() + 1
      , trend = unlisted[names(unlisted) == "estimate.mean of x"] %>% as.numeric() 
      , stderr = unlisted[names(unlisted) == "stderr"] %>% as.numeric()) %>%
  mutate(decision = ifelse(p < 0.05, "H1", "H0"))

rep_t_H1 <- rep_t_df %>% 
            # mutate(sample_size = ifelse(decision == "H0", NA, sample_size))
            filter(decision == "H1")

rep_t_summary <- 
  rep_t_H1 %>%
  # get cumulative proportion of type I error at each sample size
  # group_by(sample_size) %>%
  group_by(true_effect, sample_size) %>%
  summarise(prop = sum(decision == "H1") / ntsim,
            mean_effect = mean(trend)) %>%
  group_by(true_effect) %>%
  mutate(cum_H1 = cumsum(prop))

```

```{r plot_opt_stopping}
# rep_t_summary %>%
#   ggplot(aes(x = sample_size, y = cum_H1)) + geom_step() +
#   geom_hline(yintercept = 0.05, col = "red", linetype = "dashed") +
#   geom_point(filter(rep_t_summary, sample_size %in% c(2, 10, 20, 50, 100)), 
#              mapping = aes(x = sample_size, y = cum_H1)) +
#   geom_text(filter(rep_t_summary, sample_size %in% c(2, 10, 20, 50, 100)), 
#              mapping = aes(x = sample_size, y = cum_H1, label = round(cum_H1, digits = 2)), nudge_y = 0.05) +
#   ylim(0,1) +
#   labs(title = "Inflation of type I error by repeated tests of accumulating data",
#        y = "Probability of type I error",
#        x = "sample number",
#        caption = "Data simulated from N(0,1) \nOne-sided t-test applied after every observation") +
#   facet_wrap(~true_effect, nrow = 3)

rep_t_summary %>%
  mutate(true_effect = paste("true effect = ", true_effect)) %>%
  ggplot(aes(x = sample_size, y = cum_H1)) + geom_step() +
  geom_hline(yintercept = 0.05, col = "red", linetype = "dashed") +
  ylim(0,1) +
  facet_wrap(~true_effect, nrow = 3) +
  theme(legend.position = "n")
```

```{r}
rep_t_summary %>%
  #mutate(true_effect = paste("true effect = ", true_effect)) %>%
  ggplot(aes(x = sample_size, y = cum_H1, col = as.factor(true_effect) )) + geom_step() +
  geom_hline(yintercept = 0.05, col = "red", linetype = "dashed") +
  ylim(0,0.5) + xlim(0,25) +
  labs(title = "Optional stopping increases false alarms",
       y = "Cumulative probability of false alarm",
       x = "sample (year)",
       col = "true effect")
  
```


```{r}
# ggplot() +
#   geom_jitter(data = rep_t_H1, mapping = aes(x = sample_size, y = trend), alpha = 0.1) +
#   geom_line(data = rep_t_summary, mapping = aes(x = sample_size, y = mean_effect), size = 1.5) +
#   geom_hline(yintercept = 0, linetype = "dashed", col = "red") +
#   ylim(-0.1, 1.1) +
#   labs(title = "Bias of effect size estimates given optional stopping",
#        x = "sample number",
#        y = "Effect size estimate")

rep_t_summary %>%
  mutate(true_effect_facet = paste("true effect = ", true_effect)) %>%
  ggplot() +
  geom_jitter(data = rep_t_H1, mapping = aes(x = sample_size, y = trend), alpha = 0.01) +
  geom_line(aes(x = sample_size, y = mean_effect), size = 1.5) +
  geom_line(aes(x = sample_size, y = true_effect), linetype = "dashed") +
  facet_wrap(~true_effect_facet, nrow = 3)
```


```{r table_opt_stopping, warning = FALSE, eval = FALSE}
rep_t_df %>%
  filter(sample_size %in% c(2, 5, 10, 15, 19, 49, 100)) %>%
  summarise("Observation" = sample_size, 
            "Pr(Type I error)" = cum_H1) %>%
  knitr::kable(digits = 2)
```

As expected, optional stopping results in rejection of the null. Note that the time series for which the null was not rejected would have eventually lead to rejection. Optional stopping also results in effect size estimates that are biased.

# Sequential maximum likelihood ratio tests

### Point null hypothesis with composite alternative

```{r}
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

seq_ml_test_list <- vector("list", length = length(diff_list))

for (tseries in seq_along(diff_list)) {
  # get sequential ml estimates for current time series
  x <- diff_list[[tseries]]
  seq_mle <- run_stat(x)
  mu_vec <- seq_mle$mu_mle
  sd_mle_vec <- seq_mle$sd_mle
  sd_null_vec <- seq_mle$sd_null
  
  # initialize vectors to store LLR and decision
llr_vec <- vector("numeric", length = length(x))
decision_vec <- vector("numeric", length = length(x))
for (samp in 2:length(x)) {
  # compute log-likelihood ratio for observations 1:samp
  llr_vec[samp] <- sum(dnorm(x[1:samp], mean = mu_vec[samp], sd = sd_mle_vec[samp], log = TRUE)) -
                    sum(dnorm(x[1:samp], mean = 0, sd = sd_null_vec[samp], log = TRUE))
  # stop if llr outside of continuation region
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
  }
seq_ml_test_list[[tseries]] <- tibble(x = x, 
                             true_effect = d_true_vec[tseries],
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend = mu_vec,
                             sd = sd_mle_vec) 
}

seq_ml_df <- bind_rows(seq_ml_test_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```

```{r}
seq_ml_result <-
  seq_ml_df %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

seq_ml_result %>%
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

```{r}
seq_ml_result %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~true_effect) +
  labs(title = "Trend estimates for sequential maximum LRT")
```

### composite null and alternative

```{r}
# log likelihood of iid normal data
norm_log_lik <- function (parm, obs) {
  sum(dnorm(obs, mean = parm[1], sd = parm[2], log = TRUE))
}

# calculate constrained MLE
likelihood_fn <- function(data, # observed data
                          hypothesis = c(NA,NA),  # restrict values for mean
                          sd_bounds = c(0.001,Inf),   # restrict values for sd
                          guess) {                # initial guess for mean and sd
  opt <- optim(par = guess, fn = norm_log_lik, method = "L-BFGS-B",
      lower = c(hypothesis[1],sd_bounds[1]), 
      upper = c(hypothesis[2],sd_bounds[2]),
      control = list(fnscale = -1), # maximize log_lik
      obs = data)
  return(data.frame(mean = opt$par[1],
                    sd = opt$par[2],
                    loglikelihood = opt$value,
                    convergence = opt$convergence))
}

# define parameters
null_hyp <- c(-10, 0.249)
alt_hyp <- c(0.25,10)
```

Here I test composite null and alternative hypotheses without an indifference region:

$H_0: r <$ `r alt_hyp[1]` $; \sigma^2 > 0$

$H_1: r \geq$ `r alt_hyp[1]` $; \sigma^2 > 0$

The test is:

\begin{align}
S_0 & = 0 \\
S_t & = \ln \left( \frac{P_{\hat \theta_1}(d_{1:t})}{P_{\hat \theta_0}(d_{1:t})} \right)
\end{align}

Where $P_{\hat \theta_i}(.)$ is the normal probability density function evaluated at the maximum likelihood estimate $\theta_i = [\hat r_i,\hat \sigma_i^2]'$ given the restriction on $r$ for hypothesis $i = 0,1$ for the observed differences $d_1,\ldots, d_t$ at time $t$.

The decision boundaries are set using Wald's approximations:

$$A = \ln \frac{1-\beta}{\alpha}$$
$$B = \ln \frac{\beta}{1-\alpha}$$

Where the researcher chooses a type I ($\alpha$) and type II ($\beta$) error probability that is acceptable to their objectives.

After each observation there are three possible outcomes:

* If $S_t \in (A,B)$ then take another observation. 
* If $S_t > A$ reject $H_0$ 
* If $S_t < B$ accept $H_0$.

```{r cache = TRUE}
seq_ml_test_comp_list <- vector("list", length = length(diff_list))

for (tseries in seq_along(diff_list)) {
  x <- diff_list[[tseries]]
  
  # init storage
  alt_mean <- null_mean <- alt_sd <- null_sd <- alt_conv <- null_conv <- rep(NA_real_, length = length(x))
  llr_vec <- rep(NA_real_, length = length(x))
  decision_vec <- rep(NA_character_, length = length(x))
  
  for (samp in 2:length(x)) {
    
    # get MLE under each hypothesis
    alt <- likelihood_fn(x[1:samp],
                  hypothesis = alt_hyp,
                  guess = c(0,1))
    null <- likelihood_fn(x[1:samp],
                  hypothesis = null_hyp,
                  guess = c(0,1))
    
    # compute loglikehood ratio
    llr_vec[samp] <- alt$loglikelihood - null$loglikelihood
    
    # save parameter estimates and convergence code (0 = converged) under each hypohtesis
    alt_mean[samp] <- alt$mean
    alt_sd[samp] <- alt$sd
    alt_conv[samp] <- alt$convergence
    
    null_mean[samp] <- null$mean
    null_sd[samp] <- null$sd
    null_conv[samp] <- null$convergence
    
    
    # make decision if llr outside of continuation region
    # break loop if decision is made
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
    if (decision_vec[samp] != "?") break
  }

seq_ml_test_comp_list[[tseries]] <- tibble(x = x, 
                             true_effect = d_true_vec[tseries],
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend_alt = alt_mean,
                             sd_alt = alt_sd,
                             conv_alt = alt_conv,
                             trend_null = null_mean,
                             sd_null = null_sd,
                             conv_null = null_conv) 
}

seq_comp_test <- bind_rows(seq_ml_test_comp_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```

```{r}
seq_comp_result <-
  seq_comp_test %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

seq_comp_result %>%
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend_alt = mean(trend_alt),
            trend_null = mean(trend_null)) %>%
  knitr::kable(digits = 2)
```

```{r}
seq_comp_result %>%
  mutate(trend = case_when(decision == "H0" ~ trend_null,
                           decision == "H1" ~ trend_alt)) %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~true_effect) +
  labs(title = "Trend estimates for sequential maximum LRT")
```

```{r eval = FALSE}
# examine runs where no decision was made
# how many times did llr switch signs?
# get position and number of switches for each run
undecided <-
  seq_comp_test %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  mutate(made_decision = sum((decision == "H0" | decision == "H1"), na.rm = TRUE) > 0) %>% #pull(made_decision) %>% unique()
  filter(made_decision == FALSE) %>%
  mutate(evidence = ifelse(llr > 0, "H1", "H0")) %>%
  mutate(switched = ifelse(evidence != lag(evidence), 1, NA_real_),
         #switched = ifelse(is.na(switched), 0, switched),
         n_switch = sum(switched, na.rm = TRUE))
undecided %>%
  filter(true_effect == 0) %>%
  ggplot() +
  geom_line(aes(x = time, y = llr)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(data = filter(undecided, !is.na(switched), true_effect == 0), aes(x = time, y = llr), col = "red") +
  geom_rug(data = filter(undecided, !is.na(switched), true_effect == 0), 
           aes(x = time, y = switched), col = "red", sides = "b") +
  facet_wrap(~sim) +
  labs(title = "LLR when test never terminated (r = 0)",
       caption = "Points indicate switch between evidence for each hypothesis")

undecided %>%
  filter(true_effect == 0.5) %>%
  ggplot() +
  geom_line(aes(x = time, y = llr)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(data = filter(undecided, !is.na(switched), true_effect == 0.5), aes(x = time, y = llr), col = "red") +
  geom_rug(data = filter(undecided, !is.na(switched), true_effect == 0.5), 
           aes(x = time, y = switched), col = "red", sides = "b") +
  facet_wrap(~sim) +
  labs(title = "LLR when test never terminated (r = 0.5)",
       caption = "Points indicate switch between evidence for each hypothesis")
```

```{r}

```



# Conclusion

I will probably focus more on ad-hoc sequential maximum likelihood ratio tests over the sequential t-test. While the Wald decision boundary apporximations don't necessarily work for an these ad-hoc procedures it will be possible to obtain boundaries through simulation that yield error probabilities set by the researcher.

### Next steps before spring semester:

* sequential maximum likelihood ratio test (composite alternative)
    + simple null ($H_0: r = 0$)
    + composite null ($H_0: r \in (-r_0,r_0)$)
  
* Methods for computing bounds for tests

* Confidence intervals based on Fisher information (i.e., not dependent on sampling distribution)

* Extension to gaussian AR(1) 

### Other

* Check if the resampling method for power analyses commonly used by ecologists actually makes sense
* Reformulate as Bayesian sequential decision problems

# Ecologically relevant trends

```{r setup_eco_trend}
# simulate data for ecologically relevant parameter regions
set.seed(123)

# set params
nreplicates <- 1000
effect_size <- round(iucn_crit$trend/2, 4) %>% unique() %>% append(0)
effect_sd <- 0.1

d_true_vec <- rep(effect_size, each = nreplicates)
d_relevant <- -0.0346 # dixon pechmann, doubling/half time of 20 years
d_relevant_vec <- rep(d_relevant, length = length(d_true_vec))
tmax <- 100

# error probabilities and bounds
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

# define accept-reject regions
null_hyp <- c(d_relevant*0.99, 10)
alt_hyp <- c(-10, d_relevant)

# simulate differences
diff_list_trend <- lapply(seq_along(d_true_vec), function(x) rnorm(n = tmax, mean = d_true_vec[x], sd = effect_sd))
```

```{r dependson="setup_eco_trend"}
seq_trend_test_list <- vector("list", length = length(diff_list_trend))

for (tseries in seq_along(diff_list_trend)) {
  x <- diff_list_trend[[tseries]]
  
  # init storage
  alt_mean <- null_mean <- alt_sd <- null_sd <- alt_conv <- null_conv <- rep(NA_real_, length = length(x))
  llr_vec <- rep(NA_real_, length = length(x))
  decision_vec <- rep(NA_character_, length = length(x))
  
  for (samp in 2:length(x)) {
    
    # get MLE under each hypothesis
    alt <- likelihood_fn(x[1:samp],
                  hypothesis = alt_hyp,
                  guess = c(0,1))
    null <- likelihood_fn(x[1:samp],
                  hypothesis = null_hyp,
                  guess = c(0,1))
    
    # compute loglikehood ratio
    llr_vec[samp] <- alt$loglikelihood - null$loglikelihood
    
    # save parameter estimates and convergence code (0 = converged) under each hypohtesis
    alt_mean[samp] <- alt$mean
    alt_sd[samp] <- alt$sd
    alt_conv[samp] <- alt$convergence
    
    null_mean[samp] <- null$mean
    null_sd[samp] <- null$sd
    null_conv[samp] <- null$convergence
    
    
    # make decision if llr outside of continuation region
    # break loop if decision is made
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
    if (decision_vec[samp] != "?") break
  }

seq_trend_test_list[[tseries]] <- tibble(x = x, 
                             true_effect = d_true_vec[tseries],
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend_alt = alt_mean,
                             sd_alt = alt_sd,
                             conv_alt = alt_conv,
                             trend_null = null_mean,
                             sd_null = null_sd,
                             conv_null = null_conv) 
}

seq_comp_trend_test <- bind_rows(seq_trend_test_list, .id = "sim") %>% mutate(sim = as.numeric(sim))
```

```{r}
seq_comp_trend_result <-
  seq_comp_trend_test %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

seq_comp_trend_result %>%
  group_by(true_effect) %>%
  mutate(nreplicates = n()) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend_alt = mean(trend_alt),
            trend_null = mean(trend_null)) %>%
  slice(1) %>%
  arrange(desc(true_effect)) %>%
  knitr::kable(digits = 3)
```


The relevant effect size is `r d_relevant`

There are some convergence issues with finding the MLE.

```{r}
seq_comp_trend_result %>%
  filter(conv_alt != 0, conv_null != 0) %>%
  group_by(true_effect, decision, conv_alt, conv_null) %>%
  summarise(occurances = n()) %>%
  knitr::kable()
```


```{r}
seq_comp_trend_result %>%
  mutate(trend = case_when(decision == "H0" ~ trend_null,
                           decision == "H1" ~ trend_alt)) %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~round(true_effect,3) ) +
  labs(title = "Trend estimates for sequential maximum LRT")
```

```{r}
knitr::knit_exit()
```

### naive sequential test

Here I test simple null ($H_0: r = 0$) and alternative ($H_1: r = 0.1$) hypotheses using the likelihood ratio of sequential restricted likelihood estimates:

\begin{align}
S_0 & = 0 \\
S_t & = \ln \left( \frac{P(d_{1:t}|r = 0.1, \hat\sigma_{1,t})}{P(d_{1:t}|r = 0, \hat\sigma_{0,t})} \right)
\end{align}

Where $P(.)$ is the normal probability density function of the observed differences $d_1,\ldots, d_t$ given the hypothesized trend $r$ and the sequential maximum likelihood estimate of the sd under each hypothesis $\hat\sigma_{i,t} \text{  , }i=0,1$.

The decision boundaries are set using Wald's approximations:

$$A = \ln \frac{1-\beta}{\alpha}$$
$$B = \ln \frac{\beta}{1-\alpha}$$

Where the researcher chooses a type I ($\alpha$) and type II ($\beta$) error probability that is acceptable to their objectives.

After each observation there are three possible outcomes:

* If $S_t \in (A,B)$ then take another observation. 
* If $S_t > A$ reject $H_0$ 
* If $S_t < B$ accept $H_0$.

```{r}
seq_test <- function(diffs, min_effect = NA, true_effect = NA, type1, type2) {
  
  # run sequential test on first differences
  out <-
    run_stat(diffs, alternative = min_effect, null = 0) %>% # compute running mean and standard deviation
    mutate(loglik_alt = dnorm(x = diff_1, mean = min_effect,#max(c(min_effect, mu_mle), na.rm = TRUE) , 
                              sd = sd_mle, log = TRUE),   # loglik of difference under alternative
           loglik_null = dnorm(x = diff_1, mean = 0, sd = sd_null, log = TRUE)) %>%  # loglik of difference under null
    mutate(loglik_alt = ifelse(is.infinite(loglik_alt), NA, loglik_alt), # remove inital NA value of each log likelihood
           loglik_null = ifelse(is.infinite(loglik_null), NA, loglik_null)) %>%
    mutate(llr = cumSkipNA(loglik_alt, sum) - cumSkipNA(loglik_null, sum)) %>% # get loglikelikhood ratio
    mutate(upper = log( (1-type2) / type1), # compute wald decision boundaries
           lower = log( type2 / (1 - type1))) %>%
    mutate(decision = case_when(llr <= upper & llr >= lower ~ "?", # get decision
                                llr > upper ~ "H1",
                                llr < lower ~ "H0")) %>%
    # add other info
    mutate(time = row_number() + 1, # define timepoints
           true_effect = true_effect,
           min_effect = min_effect,
           type1 = type1,
           type2 = type2) 
  return(out)
}

get_decision <- function(data) {
    
    # get time of decision
    out <- data %>% 
      filter(decision != "?") %>% 
      arrange(time) %>%
      slice(1) %>%
      select(time, decision, min_effect, true_effect, type1, type2)
    # get naive trend estimate
    out$trend <- data %>% pull(diff_1) %>% mean(na.rm = TRUE)
    return(out)
}

```

```{r}
# get result of naive sequential test
# simple null and simple alternative
seq_test_list <-
  lapply(seq_along(d_true_vec), function(x)
       seq_test(diff_list[[x]], min_effect = d_relevant_vec[x], true_effect = d_true_vec[x], 
                type1 = 0.05, type2 = 0.2))

# get decision, sample size, and trend estimate
# simple null and alternative
seq_result_df <-
  lapply(seq_test_list, function(x) get_decision(x)) %>%
  bind_rows()
```


```{r}
seq_result_df %>%
  group_by(min_effect, true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

Note that the average sample number (asn) increases as the difference between the alternative hypothesis and true effect size increases. This is because both the null and alternative are unlikely given the observed data.

The empirical type I error probabilities exceed the nominal type I error probability when $H_0$ is false. However, the bounds on type I and II error probability are satisfied for all other parameter values.

Oddly, the estimates of the trend do not appear to be biased like I expected. (NOTE: Maximum likelihood estimates may be unaffected by stopping rules. Need to check.)


```{r}
seq_test_df <- seq_test_list %>% bind_rows(.id = "sim")

seq_test_df %>%
  group_by(sim) %>%
  mutate(time = row_number() + 1) %>%
  ggplot() +
  geom_line(aes(x = time, y = llr, group = sim), alpha = 0.3) +
  geom_hline(aes(yintercept = upper), linetype = "dashed", col = "red") +
  geom_hline(aes(yintercept = lower), linetype = "dashed", col = "red") +
  facet_wrap(~true_effect) +
  ylim(-2, 3) +
  labs(title = "Sequential log-likelihood ratios",
       caption = "Accept H0 (H1) if LLR exceeds lower (upper) bound",
       y = "log-likelihood ratio",
       x = "sample")
```


```{r}
seq_result_df %>%
  mutate(error = trend - true_effect) %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed", size = 1.2) +
  geom_point(aes(x = time, y = error, col = decision), alpha = 0.5) +
  facet_wrap(~true_effect) +
  labs(title = "Error of trend estimate upon decision",
       x = "sample",
       y = "(estimated trend) - (true trend)")
```


# Sequential t-test

\begin{align}
S_1 & = 0 \\
S_t & = \ln \left( \frac{P(t_{1:t}|df = t-1, \delta)}{P(t_{1:t}|df = t-1)} \right)
\end{align}

Where $P(.)$ is the probability density function of t-distribution for the t-statistic $\hat r /\hat\sigma$ given the $df = t - 1$ and hypothesized effect size $\delta = r/\sigma$. In this case, $\delta = 0.5$ which is consistent with the minimum relevant trend size used for the naive sequential test shown previously.

I used the Wald approximation for the decision boundaries.

```{r warning = FALSE}
# x <- diff_list[[1]]
d <- d_relevant
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

# initialize list to store results for each timeseries
ts_list <- vector("list", length = length(diff_list))

# initialize vectors to store likelihood and decision
llr_vec <- estimate_vec <- stderr_vec <- vector("numeric", length = tmax)
decision_vec <- vector("character", length = tmax)

for (tseries in seq_along(diff_list)) {
  for (samp in 2:tmax) {
    # calc t test repeatedly as data "accumulates"
    current_t <- t.test(diff_list[[tseries]][1:samp], alternative = "greater")
    ncp <- d * sqrt(samp)
    llr_vec[samp] <- dt(current_t$statistic, df = (samp - 1), ncp = ncp, log = TRUE) - 
               dt(current_t$statistic, df = (samp - 1), log = TRUE)
    
    # stop if llr outside of continuation region
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
    
    # grab updated trend estimate and standard error after every new observation
    estimate_vec[samp] <- current_t$estimate
    stderr_vec[samp] <- current_t$stderr
}
ts_list[[tseries]] <- tibble(x = diff_list[[tseries]], 
                             true_effect = d_true_vec[tseries],
                             relevant_effect = d,
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend = estimate_vec,
                             stderr = stderr_vec) 
}

seq_t_df <- bind_rows(ts_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```

```{r}
# get df of rows where first decision is made
seq_t_result <- 
  seq_t_df %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

# get operating characteristics of test
seq_t_result %>%  
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

The nominal error probabilities are met except for the case where the $r = \delta$ which accepts $H0$ at too high a probability.

```{r}
seq_t_result %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~true_effect) +
  labs(title = "Uncorrected trend estimates for sequential t-test")
```

There are clear problems with the estimates obtained after stopping using the sequential t-test. All estimates are biased in the direction of the hypothesis that is accepted.


### Autocorrelation

```{r eval = FALSE}
temp_trend <- 0.01
temp_sd <- 0.0001
temp_ar <- 0.0001
tfinal <- 200
ar1 <- arima.sim(list(order = c(1,0,0), ar = temp_ar, sd = temp_sd), n = tfinal) + temp_trend # %>% exp() %>% plot()
wn <- arima.sim(list(sd = temp_sd), n = tfinal) + temp_trend #%>% diffinv() %>% exp() %>% plot()
#diffinv(ar1)  %>% plot()

arpop <- rep(0, length = tfinal)
arpop[1] <- 1
wnpop <- arpop
for (i in 2:tfinal) {
  #tpop[i] <- exp(rnorm(1, mean = log(tpop[i-1]) + 0.01, sd = 0.1)) 
  arpop[i] <- exp(log(arpop[i-1]) + ar1[i])
  wnpop[i] <- exp(log(wnpop[i-1]) + wn[i])
}
plot(arpop/max(arpop), type = "l")
lines(wnpop/max(wnpop), lty = "dashed")
```


```{r}
# https://github.com/eastonwhite/time-series-project
load("cleaned_timeseries_database.Rdata")
# long_dat has time series data for all species in White 2018
#   popvalue has been standardized to be between [0,1]
# pop_info has data about time series characteristics and life history

long_dat

```

