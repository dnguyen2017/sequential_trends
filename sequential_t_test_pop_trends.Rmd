---
title: "Sequential t-test"
author: "David Nguyen"
date: "Compliled on `r Sys.Date()`"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Testing for linear and exponential population trends

Stochastic linear trends in population size $N_t$ for $t = 0,1,2, \ldots, T$ can be described as a Gaussian random walk with drift $r$ and environmental process standard deviation $\sigma$.

\begin{align}
N_{t+1} & \sim Normal(n_t + r, \sigma) \\
N_{0} & = n_0
\end{align}

This can also be used as a model of the log-population size $X_t$ of a model with stochastic exponential growth model with lognormal environmental noise.

\begin{align}
X_{t+1} & \sim Normal(x_t + r, \sigma) \\
X_{0} & = x_0
\end{align}

The first differences of the observed population sizes are 

\begin{align}
d_1, \ldots, d_{T-1} & =  
\begin{cases}
n_1 - n_0, \ldots, n_T - n_{T-1} \text{ for linear model} \\
x_1 - x_0, \ldots, x_T - x_{T-1} \text{ for exponential model} \\
\end{cases} \\
                     & \overset{iid}\sim Normal(r, \sigma) \\
\end{align}

Since the first difference are independent and identically distributed normal with mean equal to the (additive) linear or exponential (multiplicative) trend we can test for non-zero trends using the null hypothesis of $r = 0$ and alternative hypothesis $r \neq 0$.

```{r}
run_stat <- function(x,
                     alternative = NA,
                     null = 0) {
  # add checks here
  
  # init vectors for statistics
  m_ <- vector("numeric", length = length(x))
  s_ <- sd_0 <- s_0 <- s2_mle <- sd_mle <- s2_ <- sd_ <- m_
  
  if (is.na(alternative)) { # if alternative hypothesis is one sided and composite
    # init value of mean is x1. All other init values are 0
    m_[1] <- x[1]
    
    # calculate running statistics
    for (i in 2:length(x)) {
      m_[i] <- m_[i - 1] + (x[i] - m_[i - 1]) / i
      s_[i]  <- s_[i - 1] + (x[i] - m_[i - 1]) * (x[i] - m_[i])
      s2_mle[i] <- s_[i] / (i)
      sd_mle[i] <- sqrt(s2_mle[i])
      s2_[i] <- s_[i] / (i - 1)
      sd_[i] <- sqrt(s2_[i])
      # under null that r = 0
      s_0[i] <- s_0[i - 1] + (x[i] - 0) * (x[i] - 0)
      sd_0[i] <- sqrt(s_0[i] / i)
    }    
    
  } else { # if alternative is point hypothesis
    m_[1] <- alternative
    # calculate running statistics
    for (i in 2:length(x)) {
      m_[i] <- alternative + (x[i] - alternative) / i
      s_[i]  <- s_[i - 1] + (x[i] - alternative) * (x[i] - alternative)
      s2_mle[i] <- s_[i] / (i)
      sd_mle[i] <- sqrt(s2_mle[i])
      #s2_[i] <- s_[i]/(i-1)
      #sd_[i] <- sqrt(s2_[i])
      # under null that r = 0
      s_0[i] <- s_0[i - 1] + (x[i] - null) * (x[i] - null)
      sd_0[i] <- sqrt(s_0[i] / i)
    }
  }
  # return: id = observation number, obs = observation value, mu_mle, sd_mle, sd_corrected
  return(tidyr::tibble(
    diff_1 = x,
    mu_mle = m_,
    sd_mle,
    #sd_corrected = sd_,
    sd_null = sd_0
  )) # %>% tibble::rowid_to_column(var = "id"))
  #return(tidyr::tibble(diff_1 = c(NA,x), mu_mle = c(NA,m_), sd_mle = c(NA,sd_mle), sd_corrected = c(NA,sd_) )) # %>% tibble::rowid_to_column(var = "id"))
}

# apply FUNC cumulatively when NA are present
# https://stackoverflow.com/questions/25576358/calculate-cumsum-while-ignoring-na-values/25576972
cumSkipNA <- function(x, FUNC)
{
  d <- deparse(substitute(FUNC))
  funs <- c("max", "min", "prod", "sum")
  stopifnot(is.vector(x), is.numeric(x), d %in% funs)
  FUNC <- match.fun(paste0("cum", d))
  x[!is.na(x)] <- FUNC(x[!is.na(x)])
  x
}

```

### naive sequential test

Here I test simple null ($H_0: r = 0$) and alternative ($H_1: r = 0.1$) hypotheses using the likelihood ratio of sequential restricted likelihood estimates:

\begin{align}
S_0 & = 0 \\
S_t & = \ln \left( \frac{P(d_{1:t}|r = 0.1, \hat\sigma_{1,t})}{P(d_{1:t}|r = 0, \hat\sigma_{0,t})} \right)
\end{align}

Where $P(.)$ is the normal probability density function of the observed differences $d_1,\ldots, d_t$ given the hypothesized trend $r$ and the sequential maximum likelihood estimate of the sd under each hypothesis $\hat\sigma_{i,t} \text{  , }i=0,1$.

The decision boundaries are set using Wald's approximations:

$$A = \ln \frac{1-\beta}{\alpha}$$
$$B = \ln \frac{\beta}{1-\alpha}$$

Where the researcher chooses a type I ($\alpha$) and type II ($\beta$) error probability that is acceptable to their objectives.

After each observation there are three possible outcomes:

* If $S_t \in (A,B)$ then take another observation. 
* If $S_t > A$ reject $H_0$ 
* If $S_t < B$ accept $H_0$.

```{r}
seq_test <- function(diffs, min_effect = NA, true_effect = NA, type1, type2) {
  
  # run sequential test on first differences
  out <-
    run_stat(diffs, alternative = min_effect, null = 0) %>% # compute running mean and standard deviation
    mutate(loglik_alt = dnorm(x = diff_1, mean = min_effect,#max(c(min_effect, mu_mle), na.rm = TRUE) , 
                              sd = sd_mle, log = TRUE),   # loglik of difference under alternative
           loglik_null = dnorm(x = diff_1, mean = 0, sd = sd_null, log = TRUE)) %>%  # loglik of difference under null
    mutate(loglik_alt = ifelse(is.infinite(loglik_alt), NA, loglik_alt), # remove inital NA value of each log likelihood
           loglik_null = ifelse(is.infinite(loglik_null), NA, loglik_null)) %>%
    mutate(llr = cumSkipNA(loglik_alt, sum) - cumSkipNA(loglik_null, sum)) %>% # get loglikelikhood ratio
    mutate(upper = log( (1-type2) / type1), # compute wald decision boundaries
           lower = log( type2 / (1 - type1))) %>%
    mutate(decision = case_when(llr <= upper & llr >= lower ~ "?", # get decision
                                llr > upper ~ "H1",
                                llr < lower ~ "H0")) %>%
    # add other info
    mutate(time = row_number() + 1, # define timepoints
           true_effect = true_effect,
           min_effect = min_effect,
           type1 = type1,
           type2 = type2) 
  return(out)
}

get_decision <- function(data) {
    
    # get time of decision
    out <- data %>% 
      filter(decision != "?") %>% 
      arrange(time) %>%
      slice(1) %>%
      select(time, decision, min_effect, true_effect, type1, type2)
    # get naive trend estimate
    out$trend <- data %>% pull(diff_1) %>% mean(na.rm = TRUE)
    return(out)
}

```


```{r eval = FALSE, echo = FALSE}
d_true <- 0.9
d_relevant <- 0.1
x <- rnorm(n = 100, mean = d_true, sd = 1)
(seq_df <- seq_test(x, min_effect = d_relevant, true_effect = d_true, type1 = 0.05, type2 = 0.2))
(result_df <- get_decision(seq_df))
```


```{r cache = TRUE}
set.seed(123)

# set params
nreplicates <- 100
effect_size <- seq(0, by = 0.5, length.out = 6)
d_true_vec <- rep(effect_size, each = nreplicates)
d_relevant <- 0.5
d_relevant_vec <- rep(d_relevant, length = length(d_true_vec))
tmax <- 100

# simulate differences
diff_list <- lapply(seq_along(d_true_vec), function(x) rnorm(n = tmax, mean = d_true_vec[x], sd = 1))

# get result of naive sequential test
# simple null and simple alternative
seq_test_list <-
  lapply(seq_along(d_true_vec), function(x)
       seq_test(diff_list[[x]], min_effect = d_relevant_vec[x], true_effect = d_true_vec[x], 
                type1 = 0.05, type2 = 0.2))

# get decision, sample size, and trend estimate
# simple null and alternative
seq_result_df <-
  lapply(seq_test_list, function(x) get_decision(x)) %>%
  bind_rows()
```

```{r}
seq_result_df %>%
  group_by(min_effect, true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

Note that the average sample number (asn) increases as the difference between the alternative hypothesis and true effect size increases. This is because both the null and alternative are unlikely given the observed data.

The empirical type I error probabilities exceed the nominal type I error probability when $H_0$ is false. However, the bounds on type I and II error probability are satisfied for all other parameter values.

Oddly, the estimates of the trend do not appear to be biased like I expected. (NOTE: Maximum likelihood estimates may be unaffected by stopping rules. Need to check.)

```{r}
seq_test_df <- seq_test_list %>% bind_rows(.id = "sim")

seq_test_df %>%
  group_by(sim) %>%
  mutate(time = row_number() + 1) %>%
  ggplot() +
  geom_line(aes(x = time, y = llr, group = sim), alpha = 0.3) +
  geom_hline(aes(yintercept = upper), linetype = "dashed", col = "red") +
  geom_hline(aes(yintercept = lower), linetype = "dashed", col = "red") +
  facet_wrap(~true_effect) +
  ylim(-2, 3) +
  labs(title = "Sequential log-likelihood ratios",
       caption = "Accept H0 (H1) if LLR exceeds lower (upper) bound",
       y = "log-likelihood ratio",
       x = "sample")
```


```{r}
seq_result_df %>%
  mutate(error = trend - true_effect) %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed", size = 1.2) +
  geom_point(aes(x = time, y = error, col = decision), alpha = 0.5) +
  facet_wrap(~true_effect) +
  labs(title = "Error of trend estimate upon decision",
       x = "sample",
       y = "(estimated trend) - (true trend)")
```


### sample size for fixed-sample one-sided t test
```{r}
# fixed sample size effect size for one sided t-test
# assume sd is known
tibble(effect_size = effect_size[effect_size > 0]) %>%
  rowwise() %>%
  mutate(sample_size =  power.t.test(delta = effect_size, sd = 1, sig.level = 0.05, power = 0.8, 
                                     type = "one.sample", alternative = "one.sided")$n,
         sample_size = ceiling(sample_size)) %>%
  # rowwise() %>%
  # mutate(sample_size = power_t$n)
  knitr::kable()
```

Sample size calculations for the fixed sample test assume that the unknown parameters $r,\sigma$ are known. For these sample size calculations I set a 0.05 type I error rate, 0.8 power which is the same as the nominal error probabilities I used for the sequential test.

### Effect of optional stopping on error rates for fixed-sample t-test

```{r}
# initialize list to store results
ttest_list <- vector("list", length = length(diff_list))

# for each time series, apply the one sided t-test after every observation
# stop and make decision at first time p < 0.05
# return a list containing t.test object
for (tseries in seq_along(diff_list)) {
  
  for (samp in 2:tmax) {
    # calc t test repeatedly as data "accumulates"
    ttest_list[[tseries]] <- t.test(diff_list[[tseries]][1:samp], alternative = "greater", conf.level = 0.95)
    
    # stop if p-value < 0.05
    if (ttest_list[[tseries]]$p.value < 0.05) break
  }
}

# make a df from the list of t.test objects
unlisted <- unlist(ttest_list)
rep_t_df <- tibble(true_effect = d_true_vec
      ,p = unlisted[names(unlisted) == "p.value"] %>% as.numeric()
      , sample_size = unlisted[names(unlisted) == "parameter.df"] %>% as.numeric() + 1
      , trend = unlisted[names(unlisted) == "estimate.mean of x"] %>% as.numeric() 
      , stderr = unlisted[names(unlisted) == "stderr"] %>% as.numeric() ) %>%
  mutate(decision = ifelse(p < 0.05, "H1", "H0"))

```

```{r plot_opt_stopping}
rep_t_df %>%
  ggplot() +
  geom_point(aes(x = sample_size, y = trend - true_effect, col = decision)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~true_effect) +
  labs(title = "T-test with optional stopping",
       caption = "t-test applied after every observation, stopped when p < 0.05")
```


```{r table_opt_stopping, warning = FALSE}
rep_t_df %>%
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/n(),
            reject = sum(decision == "H1")/n(),
            asn = ceiling(mean(sample_size)),
            estimate = mean(trend)) %>%
  knitr::kable(digits = 2)
```

As expected, optional stopping results in rejection of the null. Note that the time series for which the null was not rejected would have eventually lead to rejection. Optional stopping also results in effect size estimates that are biased.

# Sequential t-test

\begin{align}
S_1 & = 0 \\
S_t & = \ln \left( \frac{P(t_{1:t}|df = t-1, \delta)}{P(t_{1:t}|df = t-1)} \right)
\end{align}

Where $P(.)$ is the probability density function of t-distribution for the t-statistic $\hat r /\hat\sigma$ given the $df = t - 1$ and hypothesized effect size $\delta = r/\sigma$. In this case, $\delta = 0.5$ which is consistent with the minimum relevant trend size used for the naive sequential test shown previously.

I used the Wald approximation for the decision boundaries.

```{r warning = FALSE}
# x <- diff_list[[1]]
d <- d_relevant
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

# initialize list to store results for each timeseries
ts_list <- vector("list", length = length(diff_list))

# initialize vectors to store likelihood and decision
llr_vec <- estimate_vec <- stderr_vec <- vector("numeric", length = tmax)
decision_vec <- vector("character", length = tmax)

for (tseries in seq_along(diff_list)) {
  for (samp in 2:tmax) {
    # calc t test repeatedly as data "accumulates"
    current_t <- t.test(diff_list[[tseries]][1:samp], alternative = "greater")
    ncp <- d * sqrt(samp)
    llr_vec[samp] <- dt(current_t$statistic, df = (samp - 1), ncp = ncp, log = TRUE) - 
               dt(current_t$statistic, df = (samp - 1), log = TRUE)
    
    # stop if llr outside of continuation region
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
    
    # grab updated trend estimate and standard error after every new observation
    estimate_vec[samp] <- current_t$estimate
    stderr_vec[samp] <- current_t$stderr
}
ts_list[[tseries]] <- tibble(x = diff_list[[tseries]], 
                             true_effect = d_true_vec[tseries],
                             relevant_effect = d,
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend = estimate_vec,
                             stderr = stderr_vec) 
}

seq_t_df <- bind_rows(ts_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```

```{r}
# get df of rows where first decision is made
seq_t_result <- 
  seq_t_df %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

# get operating characteristics of test
seq_t_result %>%  
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

The nominal error probabilities are met except for the case where the $r = \delta$ which accepts $H0$ at too high a probability.

```{r}
seq_t_result %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~true_effect) +
  labs(title = "Uncorrected trend estimates for sequential t-test")
```

There are clear problems with the estimates obtained after stopping using the sequential t-test. All estimates are biased in the direction of the hypothesis that is accepted.

# Sequential maximum likelihood ratio tests

### Point null hypothesis

```{r}
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

seq_ml_test_list <- vector("list", length = length(diff_list))

for (tseries in seq_along(diff_list)) {
  # get sequential ml estimates for current time series
  x <- diff_list[[tseries]]
  seq_mle <- run_stat(x)
  mu_vec <- seq_mle$mu_mle
  sd_mle_vec <- seq_mle$sd_mle
  sd_null_vec <- seq_mle$sd_null
  
  # initialize vectors to store LLR and decision
llr_vec <- vector("numeric", length = length(x))
decision_vec <- vector("numeric", length = length(x))
for (samp in 2:length(x)) {
  # compute log-likelihood ratio for observations 1:samp
  llr_vec[samp] <- sum(dnorm(x[1:samp], mean = mu_vec[samp], sd = sd_mle_vec[samp], log = TRUE)) -
                    sum(dnorm(x[1:samp], mean = 0, sd = sd_null_vec[samp], log = TRUE))
  # stop if llr outside of continuation region
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
  }
seq_ml_test_list[[tseries]] <- tibble(x = x, 
                             true_effect = d_true_vec[tseries],
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend = mu_vec,
                             sd = sd_mle_vec) 
}

seq_ml_df <- bind_rows(seq_ml_test_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```

```{r}
seq_ml_result <-
  seq_ml_df %>%
  group_by(sim) %>%
  mutate(time = row_number()) %>%
  filter(decision == "H0" | decision == "H1") %>%
  slice(1)

seq_ml_result %>%
  group_by(true_effect) %>%
  summarise(accept = sum(decision == "H0")/nreplicates,
            reject = sum(decision == "H1")/nreplicates,
            no_decision = 1 - accept - reject,
            asn = ceiling(mean(time)),
            trend = mean(trend)) %>%
  knitr::kable(digits = 2)
```

```{r}
seq_ml_result %>%
  ggplot() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(aes(x = time, y = trend - true_effect, col = decision)) +
  facet_wrap(~true_effect) +
  labs(title = "Trend estimates for sequential maximum LRT")
```

# Conclusion

I will probably focus more on ad-hoc sequential maximum likelihood ratio tests over the sequential t-test. While the Wald decision boundary apporximations don't necessarily work for an these ad-hoc procedures it will be possible to obtain boundaries through simulation that yield error probabilities set by the researcher.

### Next steps before spring semester:

* sequential maximum likelihood ratio test (composite alternative)
    + simple null ($H_0: r = 0$)
    + composite null ($H_0: r \in (-r_0,r_0)$)
  
* Methods for computing bounds for tests

* Extension to gaussian AR(1) 

### Other

* Check if the resampling method for power analyses commonly used by ecologists actually makes sense
* Reformulate as Bayesian sequential decision problems

```{r}
knitr::knit_exit()
```

### composite null

```{r}
d <- 0.5
type1 <- 0.05
type2 <- 0.2
upper <- log( (1-type2) / type1)
lower <- log( type2 / (1 - type1))

seq_ml_test_list <- vector("list", length = length(diff_list))

for (tseries in seq_along(diff_list)) {
  # get sequential ml estimates for current time series
  x <- diff_list[[tseries]]
  seq_mle <- run_stat(x)
  mu_vec <- seq_mle$mu_mle
  sd_mle_vec <- seq_mle$sd_mle
  sd_null_vec <- seq_mle$sd_null
  
  # initialize vectors to store LLR and decision
llr_vec <- vector("numeric", length = length(x))
decision_vec <- vector("numeric", length = length(x))
for (samp in 2:length(x)) {
  # compute log-likelihood ratio for observations 1:samp
  llr_vec[samp] <- sum(dnorm(x[1:samp], mean = mu_vec[samp], sd = sd_mle_vec[samp], log = TRUE)) -
                    sum(dnorm(x[1:samp], mean = 0, sd = sd_null_vec[samp], log = TRUE))
  # stop if llr outside of continuation region
    decision_vec[samp] <- case_when(llr_vec[samp] <= upper & llr_vec[samp] >= lower ~ "?", # get decision
                                llr_vec[samp] > upper ~ "H1",
                                llr_vec[samp] < lower ~ "H0")
  }
seq_ml_test_list[[tseries]] <- tibble(x = x, 
                             true_effect = d_true_vec[tseries],
                             llr = llr_vec, 
                             decision = decision_vec,
                             trend = mu_vec,
                             sd = sd_mle_vec) 
}

seq_ml_df <- bind_rows(seq_ml_test_list, .id = "sim") %>% mutate(sim = as.numeric(sim))

```


```{r eval = FALSE}
arima.sim(list(order = c(1,0,0), ar = 0.5, sd = 0.1), n = 100) %>% plot()
arima.sim(list(sd = 0.1), n = 100) %>% plot()
```


